{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA + Word2Vec 사용시\n",
    "#### Word2Vec과 LDA를 통합해 사용하면 Word2Vec의 문맥적 관계뿐만 아니라 LDA의 문서와 주제간의 관계를 얻을 수 있음\n",
    "    (참고문헌 : WANG, Zhibo; MA, Long; ZHANG, Yanqing. A hybrid document feature extraction method using latent Dirichlet allocation and word2vec. In: Data Science in Cyberspace (DSC), IEEE International Conference on. IEEE, 2016. p. 98-103.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>kind_of_games</th>\n",
       "      <th>user_name</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "      <th>thumb_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>retr0</td>\n",
       "      <td>Counter-strike(1.0 - 1.6 not source) is one of...</td>\n",
       "      <td>10</td>\n",
       "      <td>26//26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>sinadoom</td>\n",
       "      <td>After all these years this shooter remains to ...</td>\n",
       "      <td>8</td>\n",
       "      <td>6//6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>Gratson</td>\n",
       "      <td>The greatest multiplayer shooter experience I'...</td>\n",
       "      <td>10</td>\n",
       "      <td>3//3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>PevMaster</td>\n",
       "      <td>The year was 2000. Half-Life had already taken...</td>\n",
       "      <td>10</td>\n",
       "      <td>3//3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Counter-Strike</td>\n",
       "      <td>rp4prez</td>\n",
       "      <td>One of the best games of all time... Never for...</td>\n",
       "      <td>10</td>\n",
       "      <td>3//3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   kind_of_games  user_name  \\\n",
       "0   0  Counter-Strike      retr0   \n",
       "1   1  Counter-Strike   sinadoom   \n",
       "2   2  Counter-Strike    Gratson   \n",
       "3   3  Counter-Strike  PevMaster   \n",
       "4   4  Counter-Strike    rp4prez   \n",
       "\n",
       "                                              review  score thumb_count  \n",
       "0  Counter-strike(1.0 - 1.6 not source) is one of...     10      26//26  \n",
       "1  After all these years this shooter remains to ...      8        6//6  \n",
       "2  The greatest multiplayer shooter experience I'...     10        3//3  \n",
       "3  The year was 2000. Half-Life had already taken...     10        3//3  \n",
       "4  One of the best games of all time... Never for...     10        3//3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\User\\Desktop\\game_word2vec\\review_data_all.csv\",encoding='cp949')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = set(data['kind_of_games'])\n",
    "\n",
    "names_words=[]\n",
    "for x in names:\n",
    "    names_words += [word.lower() for word in x.split()]\n",
    "\n",
    "cnt = collections.Counter()\n",
    "for x in names_words:\n",
    "    cnt[x] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DATA 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = [re for re in data['review']]\n",
    "\n",
    "# stemming\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "stem_review = []\n",
    "for ii, words in enumerate(review):\n",
    "    print(\"stemmer--> \", ii, \"/\", len(review))\n",
    "    stem_review.append(stemmer.stem(words))\n",
    "\n",
    "stem_review = np.array(stem_review)\n",
    "def eli_stop(string, stop_word, rlc = ''):\n",
    "    for sw in stop_word:\n",
    "        string= string.replace(sw, rlc)\n",
    "    return string\n",
    "\n",
    "\n",
    "eli = ['nothing','better','way','nice','new','great','awesome','more','lot', 'many', 'other', 'time', 'same', 'everything', 'hours', 'things', 'bit', 'most','much',\"good\", \"bad\",\"!\", \"...\", \")\", \"(\", \"/\", \".\", \",\", \"?\", \"-\", \"''\", \"``\", \"'d\", \":\", \";\", \"***\", \"*\", \"%\", \"$\", \"@\", \"#\", \"&\", \"+\", \"~\", \"'s\", \"n't\", \"'m\", \"game\",\"'\"]\n",
    "eli_review_list = [eli_stop(str(rm),eli) for rm in stem_review]\n",
    "\n",
    "sens = [nltk.tokenize.sent_tokenize(eli_list) for eli_list in eli_review_list]\n",
    "\n",
    "tokens = []\n",
    "for i in range(0, len(sens)):\n",
    "    token = []\n",
    "    for j in range(0, len(sens[i])):\n",
    "        token += nltk.tokenize.word_tokenize(sens[i][j])\n",
    "    tokens.append(list(token))\n",
    "\n",
    "pos = []\n",
    "for t in tokens:\n",
    "    pos_tokens = [token for token, pos in nltk.pos_tag(t) if pos.startswith('NN')|pos.startswith('JJ')]\n",
    "    pos.append(pos_tokens)\n",
    "\n",
    "collections.OrderedDict(sorted(cnt.items(), key=lambda t: t[1]))\n",
    "\n",
    "np.shape(pos)\n",
    "len(np.unique(pos))\n",
    "\n",
    "# removal stopwords\n",
    "stop = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "additionalstop = ['lot', 'many', 'other', 'time', 'same', 'everything', 'hours', 'things', 'bit', 'most','much','more','good','bad','sure','fun','great','game','make', 'un', 'es', 'juego', 'la', 'el', 'con', 'lo', 'los', 'para', 'una', 'si', 'se', 'por', 'le','rollerskates']\n",
    "stop += additionalstop\n",
    "stop += names_words\n",
    "\n",
    "removed_words = [a for a in pos if a not in stop]\n",
    "ree = [a for i in removed_words for a in i]\n",
    "removed_voc = list(set(ree))\n",
    "\n",
    "len(set(removed_voc))\n",
    "\n",
    "\n",
    "one_list = []\n",
    "for i in ree:\n",
    "    one_list.append([i[l] for l in range(len(i)) if len(i[l])<2])\n",
    "\n",
    "clean_words = [a for a in removed_words if a not in one_list]\n",
    "\n",
    "final_words = []\n",
    "for a_line in removed_words:\n",
    "        final_words.append([a_line[a_num] for a_num in range(len(a_line)) if len(str(a_line[a_num]))>1])\n",
    "\n",
    "final_words_list = [a for i in final_words for a in i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* matrix 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "embedding_model = Word2Vec(final_words, size=100, window = 3,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec + LDA matrix\n",
    "\n",
    "# word2vec mat\n",
    "em_mat=[]\n",
    "row_name = []\n",
    "for ii, list_words in enumerate(final_words):\n",
    "    for i in list_words:\n",
    "        if i in embedding_model:\n",
    "            em_mat.append(embedding_model[str(i)])\n",
    "            row_name.append(i)\n",
    "    print('turn-->', ii, \"/\", len(final_words))\n",
    "\n",
    "mat_list = pd.DataFrame(em_mat,index=[row_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source</td>\n",
       "      <td>0.618804</td>\n",
       "      <td>0.145858</td>\n",
       "      <td>0.523411</td>\n",
       "      <td>0.520021</td>\n",
       "      <td>-0.173712</td>\n",
       "      <td>0.307795</td>\n",
       "      <td>0.899815</td>\n",
       "      <td>-0.181912</td>\n",
       "      <td>0.403240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105109</td>\n",
       "      <td>0.186894</td>\n",
       "      <td>0.321012</td>\n",
       "      <td>0.387029</td>\n",
       "      <td>-0.191796</td>\n",
       "      <td>-0.284091</td>\n",
       "      <td>-0.947530</td>\n",
       "      <td>0.204489</td>\n",
       "      <td>0.359828</td>\n",
       "      <td>0.118231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greatest</td>\n",
       "      <td>-0.063686</td>\n",
       "      <td>0.364259</td>\n",
       "      <td>-0.309629</td>\n",
       "      <td>1.098529</td>\n",
       "      <td>-0.461379</td>\n",
       "      <td>0.411075</td>\n",
       "      <td>0.584363</td>\n",
       "      <td>-0.409022</td>\n",
       "      <td>0.423578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340206</td>\n",
       "      <td>0.212385</td>\n",
       "      <td>0.054433</td>\n",
       "      <td>-0.162662</td>\n",
       "      <td>-0.898852</td>\n",
       "      <td>-0.235662</td>\n",
       "      <td>-0.270714</td>\n",
       "      <td>-0.339825</td>\n",
       "      <td>0.161816</td>\n",
       "      <td>-0.001008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>esport</td>\n",
       "      <td>-0.017050</td>\n",
       "      <td>-0.032554</td>\n",
       "      <td>-0.009539</td>\n",
       "      <td>0.070001</td>\n",
       "      <td>-0.023072</td>\n",
       "      <td>0.016093</td>\n",
       "      <td>0.097661</td>\n",
       "      <td>-0.044066</td>\n",
       "      <td>0.129004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.017711</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.035074</td>\n",
       "      <td>-0.103017</td>\n",
       "      <td>-0.033291</td>\n",
       "      <td>-0.054472</td>\n",
       "      <td>-0.055531</td>\n",
       "      <td>0.057393</td>\n",
       "      <td>0.043367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0     source  0.618804  0.145858  0.523411  0.520021 -0.173712  0.307795   \n",
       "1   greatest -0.063686  0.364259 -0.309629  1.098529 -0.461379  0.411075   \n",
       "2     esport -0.017050 -0.032554 -0.009539  0.070001 -0.023072  0.016093   \n",
       "\n",
       "          6         7         8    ...           90        91        92  \\\n",
       "0  0.899815 -0.181912  0.403240    ...     0.105109  0.186894  0.321012   \n",
       "1  0.584363 -0.409022  0.423578    ...     0.340206  0.212385  0.054433   \n",
       "2  0.097661 -0.044066  0.129004    ...     0.005854  0.017711  0.000467   \n",
       "\n",
       "         93        94        95        96        97        98        99  \n",
       "0  0.387029 -0.191796 -0.284091 -0.947530  0.204489  0.359828  0.118231  \n",
       "1 -0.162662 -0.898852 -0.235662 -0.270714 -0.339825  0.161816 -0.001008  \n",
       "2  0.035074 -0.103017 -0.033291 -0.054472 -0.055531  0.057393  0.043367  \n",
       "\n",
       "[3 rows x 101 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_list = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\word2vec\\word2vec_word.csv\",encoding='cp949')\n",
    "mat_list.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countvec = CountVectorizer(analyzer='word',vocabulary=list(set(final_words_list)))\n",
    "count = countvec.fit_transform(final_words_list)\n",
    "topic_vocab=countvec.get_feature_names()\n",
    "titles = names\n",
    "\n",
    "# LDA modeling\n",
    "model = lda.LDA(n_topics=12, n_iter=500, random_state=6, alpha=0.1)\n",
    "model.fit(count)\n",
    "topic_word = np.array(topic_vocab)[np.argsort(model.topic_word_)][:,:-1]\n",
    "\n",
    "# lda percent\n",
    "word_topic = np.array(np.argsort(model.topic_word_))[:,::-1]\n",
    "np.shape(word_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![vector](https://github.com/Oh-Yoojin/Review-Analysis/blob/master/pictures/vector.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine model - topic vector --------------------\n",
    "lda_mat = []\n",
    "for ii, wor in enumerate(topic_word):\n",
    "    print(\"turn--> \", ii, '/', len(topic_word))\n",
    "    wor_vec = []\n",
    "    for wo in wor:\n",
    "        wor_vec.append(embedding_model[wo])\n",
    "    lda_mat.append(wor_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_range=range(12)\n",
    "\n",
    "theta_i = []\n",
    "for n, i in enumerate(topic_range):\n",
    "    print(\"turn--> \", n, \"/\", len(topic_range))\n",
    "    topic_theta = [topic/sum(word_topic[i]) for topic in word_topic[i]]\n",
    "    theta_i.append(topic_theta)\n",
    "\n",
    "topic_vectors = []\n",
    "for a in range(12):\n",
    "    cal_theta = [lda_mat[a][i]*theta_i[a][i] for i in range(len(lda_mat[a]))]\n",
    "    topic_vectors.append(cal_theta)\n",
    "\n",
    "topic_vec_final = [np.array(topic_vectors[i]).sum(axis=0) for i in topic_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comb modeling - document vector ---------------------------------\n",
    "\n",
    "fi_sent_word = pd.DataFrame(final_words)\n",
    "\n",
    "game = np.array(data['kind_of_games'])\n",
    "len(names)\n",
    "data.columns[:]\n",
    "\n",
    "review_data = data['kind_of_games']\n",
    "review_data = pd.DataFrame(review_data)\n",
    "\n",
    "total_docu_vec = []\n",
    "for n, docu in enumerate(final_words):\n",
    "    print('trun--> ', n, '/', len(final_words))\n",
    "    docu_vector = []\n",
    "    for wo in docu:\n",
    "        docu_vector.append(embedding_model[wo])\n",
    "    total_docu_vec.append(docu_vector)\n",
    "\n",
    "\n",
    "game_name = list(names)\n",
    "game = np.array(data['kind_of_games'])\n",
    "\n",
    "game_re_vec = []\n",
    "for n, na in enumerate(game_name):\n",
    "    print(\"turn--> \", n, \"/\", len(names))\n",
    "    what_game = []\n",
    "    for ga in range(len(game)):\n",
    "        if na == game[ga]:\n",
    "            what_game.append(total_docu_vec[ga])\n",
    "    game_re_vec.append(what_game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sum_mat = []\n",
    "for line in range(len(game_re_vec)):\n",
    "    print('turn--> ', line, '/', len(game_re_vec))\n",
    "    game_line = [a for i in game_re_vec[line] for a in i]\n",
    "    sum_line = []\n",
    "    for num in range(100):\n",
    "        tmp = [sum(game_line[n][num] for n in range(len(game_line)))/len(game_line)]\n",
    "        sum_line.append(tmp)\n",
    "    sum_mat.append(sum_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance ------------------------------------\n",
    "\n",
    "dist_mat = []\n",
    "for p in range(len(sum_mat)):\n",
    "    print(\"turn--> \", p, '/', len(sum_mat))\n",
    "    x_vec = [a for i in sum_mat[p] for a in i]\n",
    "    dist = [euclidean_distances(x_vec,topic_vector[n]).tolist() for n in range(len(topic_vector))]\n",
    "    bb = [a for i in dist for a in i]\n",
    "    dist_mat.append([a for i in bb for a in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.507636</td>\n",
       "      <td>4.508133</td>\n",
       "      <td>4.506932</td>\n",
       "      <td>4.507457</td>\n",
       "      <td>4.505924</td>\n",
       "      <td>4.505517</td>\n",
       "      <td>4.506538</td>\n",
       "      <td>4.506559</td>\n",
       "      <td>4.505094</td>\n",
       "      <td>4.507807</td>\n",
       "      <td>4.504379</td>\n",
       "      <td>4.508221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.873360</td>\n",
       "      <td>3.873759</td>\n",
       "      <td>3.872551</td>\n",
       "      <td>3.873103</td>\n",
       "      <td>3.871565</td>\n",
       "      <td>3.871041</td>\n",
       "      <td>3.871916</td>\n",
       "      <td>3.872049</td>\n",
       "      <td>3.870439</td>\n",
       "      <td>3.873375</td>\n",
       "      <td>3.870060</td>\n",
       "      <td>3.873853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.962925</td>\n",
       "      <td>3.963367</td>\n",
       "      <td>3.962256</td>\n",
       "      <td>3.962882</td>\n",
       "      <td>3.961172</td>\n",
       "      <td>3.960739</td>\n",
       "      <td>3.961619</td>\n",
       "      <td>3.961596</td>\n",
       "      <td>3.960179</td>\n",
       "      <td>3.963042</td>\n",
       "      <td>3.959623</td>\n",
       "      <td>3.963456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3.764286</td>\n",
       "      <td>3.764648</td>\n",
       "      <td>3.763470</td>\n",
       "      <td>3.764056</td>\n",
       "      <td>3.762398</td>\n",
       "      <td>3.762029</td>\n",
       "      <td>3.762873</td>\n",
       "      <td>3.762921</td>\n",
       "      <td>3.761468</td>\n",
       "      <td>3.764369</td>\n",
       "      <td>3.760894</td>\n",
       "      <td>3.764794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.687355</td>\n",
       "      <td>3.687870</td>\n",
       "      <td>3.686677</td>\n",
       "      <td>3.687280</td>\n",
       "      <td>3.685580</td>\n",
       "      <td>3.685187</td>\n",
       "      <td>3.686110</td>\n",
       "      <td>3.686037</td>\n",
       "      <td>3.684571</td>\n",
       "      <td>3.687498</td>\n",
       "      <td>3.683966</td>\n",
       "      <td>3.687880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0           0  4.507636  4.508133  4.506932  4.507457  4.505924  4.505517   \n",
       "1           1  3.873360  3.873759  3.872551  3.873103  3.871565  3.871041   \n",
       "2           2  3.962925  3.963367  3.962256  3.962882  3.961172  3.960739   \n",
       "3           3  3.764286  3.764648  3.763470  3.764056  3.762398  3.762029   \n",
       "4           4  3.687355  3.687870  3.686677  3.687280  3.685580  3.685187   \n",
       "\n",
       "          6         7         8         9        10        11  \n",
       "0  4.506538  4.506559  4.505094  4.507807  4.504379  4.508221  \n",
       "1  3.871916  3.872049  3.870439  3.873375  3.870060  3.873853  \n",
       "2  3.961619  3.961596  3.960179  3.963042  3.959623  3.963456  \n",
       "3  3.762873  3.762921  3.761468  3.764369  3.760894  3.764794  \n",
       "4  3.686110  3.686037  3.684571  3.687498  3.683966  3.687880  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\word2vec\\distance_mat.csv\")\n",
    "distance.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select topic ----------------------------------------\n",
    "\n",
    "selected_topic = [np.argsort(dist_to[n])[:5] for n in range(len(dist_to))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   0  1  2  3  4\n",
       "0           0  10  8  5  4  6\n",
       "1           1  10  8  5  4  6\n",
       "2           2  10  8  5  4  7\n",
       "3           3  10  8  5  4  6\n",
       "4           4  10  8  5  4  7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_topic = pd.read_csv(r\"C:\\Users\\User\\PycharmProjects\\word2vec\\dist_topic.csv\")\n",
    "selected_topic.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
